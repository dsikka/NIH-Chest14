{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as func\n",
    "import torch.utils.model_zoo as model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The argument for ResNet: Having really deep networks struggle with optimization\n",
    "# issues (even when batch normalization is used) and it was argued that this\n",
    "# underfitting was not due to vanishing gradients (happens in very deep networks)\n",
    "# as it is seen in even deep networks\n",
    "\n",
    "# If the block is the first block of the layer, then the out_ch is double\n",
    "# the in_channels, otherwise, they are the same\n",
    "\n",
    "# Downsampling achieved by increasing the stride as opposed to maxpooling\n",
    "# Stride of 2 is used in the first block of each layer to downsample\n",
    "class ResBlock(torch.nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, stride):\n",
    "        # Kernel size of 3 for all and padding of 1 for all \n",
    "        super(ResBlock, self).__init__()\n",
    "        self.k_size = 3\n",
    "        self.padding = 1\n",
    "        self.conv_bn_1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_ch, out_ch, self.k_size, stride, self.padding),\n",
    "            torch.nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "        self.conv_bn_2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(out_ch, out_ch, self.k_size, stride, self.padding),\n",
    "            torch.nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "  \n",
    "  # Forward prop for the residual block\n",
    "    def forward(self, x): \n",
    "        conv_1_output = self.conv_bn_1(x)\n",
    "        actv_output_1 = func.relu(conv_1_output)\n",
    "        conv_2_output = self.conv_bn_2(actv_output_1)\n",
    "        return func.relu(conv_2_output + x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Structure: trained on ImageNet\n",
    "# ResNet34\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        # May have to adjust if 1) Input image is greyscale 2) Input size is different\n",
    "        # given the formula O = (I + 2P - K)/S + 1\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3 , out_channels=64, kernel_size=7,\n",
    "                                     stride=2, padding=3)\n",
    "        self.bn = torch.nn.BatchNorm2d(64)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # Returns a list with all the blocks \n",
    "        self.first_layer = self.add_resnet_layer(in_ch=64, out_ch=64, layer_size=3)\n",
    "        self.second_layer = self.add_resnet_layer(in_ch=64, out_ch=128, layer_size=4)\n",
    "        self.third_layer = self.add_resnet_layer(in_ch=128, out_ch=256, layer_size=6)\n",
    "        self.fourth_layer = self.add_resnet_layer(in_ch=256, out_ch=512, layer_size=3)\n",
    "        # Keeps channels put finds the global average as opposed to the max of a \n",
    "        # 2 by 2 window. Finaly output is 1by1byn_channels\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.output_layer = torch.nn.Linear(512, n_classes)\n",
    "\n",
    "    # layer_size = number of times the block repeats  \n",
    "    def add_resnet_layer(self, in_ch, out_ch, layer_size):\n",
    "        first_block = ResBlock(in_ch, out_ch, 2)\n",
    "        blocks = [first_block]\n",
    "        for i in range(1, layer_size):\n",
    "          blocks.append(ResBlock(out_ch, out_ch, 1))\n",
    "        # Unpack torch modules into Sequential layers\n",
    "        blocks = torch.nn.Sequential(*blocks)\n",
    "        return blocks\n",
    "  \n",
    "    def forward(self, x):\n",
    "        # Go through convolutional layer\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn(out)\n",
    "        out = func.relu(out)\n",
    "        out = self.maxpool1(out)\n",
    "\n",
    "        # Basic Block layers\n",
    "        out = self.first_layer(out)\n",
    "        out = self.second_layer(out)\n",
    "        out = self.third_layer(out)\n",
    "        out = self.fourth_layer(out)\n",
    "\n",
    "        # Average pooling and fully connected layers\n",
    "        out = self.avgpool(out)\n",
    "        out = Variable(out.view(-1, 512))\n",
    "        return self.output_layer(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
